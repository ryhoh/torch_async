{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN IN JUPYTER\n",
    "このノートブックはニューラルネットワークの準同期式更新アルゴリズムを初めて使う人のためのチュートリアルです\n",
    "\n",
    "このチュートリアルを通して、準同期式の再学習を体験してみましょう"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 必要なライブラリをインストールしよう\n",
    "\n",
    "このモデルはPyTorchで実装されています"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセット\n",
    "from procedure.preprocess import cifar_10_for_vgg_loaders as cifar10\n",
    "# フレームワーク\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "# 準同期式レイヤ\n",
    "from layers.static import OptimizedSemiSyncLinear\n",
    "# モデル\n",
    "from torchvision.models import vgg\n",
    "# 評価、更新用関数\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# 時間\n",
    "import datetime\n",
    "# 統計的な評価\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 乱数シードを固定しよう\n",
    "\n",
    "プログラム内で実行するたびに違う数字を発生させる場合があります。\n",
    "そうなった場合、出力された結果がアルゴリズムの差によるものなのか、それとも乱数によるものなのかがわからなくなります。\n",
    "それを防ぐために、乱数シードを固定しておきましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 学習データを読み込もう\n",
    "\n",
    "このノートブックではcifer10というデータセットを利用します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = cifar10()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. モデルを読み込もう\n",
    "\n",
    "このノートブックではvgg16というモデルを利用します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg.vgg16()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 準同期式に変更しよう\n",
    "\n",
    "vgg16の全結合層を順同期式に変更しましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier[0] = OptimizedSemiSyncLinear(model.classifier[0])\n",
    "model.classifier[3] = OptimizedSemiSyncLinear(model.classifier[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. モデルを学習モードに変更しよう\n",
    "\n",
    "PyTorchのモデルには評価モード(eval)と学習モード(train)があります\n",
    "今回は再学習をさせるので、学習モードにしておきましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): OptimizedSemiSyncLinear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): OptimizedSemiSyncLinear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 評価関数と最適化関数を定義しよう\n",
    "\n",
    "逆伝播をする前に、順伝播で得られた結果を**評価**します。\n",
    "そして、評価値(loss)をもとに逆伝播を行い、各パラメータを**最適化**していきます。\n",
    "\n",
    "このときの評価と最適化に使う関数を定義しておきましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. GPUを使ってみよう\n",
    "\n",
    "この学習を行う際にはたくさんの計算が行われます。CPUだけでは時間がかるのでGPUを使ってみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 学習の流れを定義しよう\n",
    "\n",
    "学習を１回するたびに以下のプログラムを動かす必要があります。\n",
    "\n",
    "1. データの読み込み\n",
    "2. 勾配の初期化\n",
    "3. 順伝播\n",
    "4. 評価\n",
    "5. 逆伝播\n",
    "6. パラメータ更新\n",
    "\n",
    "これらのプログラムは何回も実行するものなので、１つの関数として定義しておきましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    total_loss = 0\n",
    "    total_size = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # データセットをGPUに対応\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # 勾配を初期化\n",
    "        optimizer.zero_grad()\n",
    "        # forward-prop\n",
    "        output = model(data)\n",
    "        # 評価しlossを計算\n",
    "        loss = criterion(output, target)\n",
    "        total_loss += loss.item()\n",
    "        total_size += data.size(0)\n",
    "        # back-prop\n",
    "        loss.backward()\n",
    "        # パラメータ更新\n",
    "        optimizer.step()\n",
    "        if batch_idx % 1000 == 0:\n",
    "            now = datetime.datetime.now()\n",
    "            print('[{}] Train Epoch: {}\\tAverage loss: {:.6f}'.format(\n",
    "                now,\n",
    "                epoch,\n",
    "                total_loss / total_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.繰り返し学習させよう\n",
    "\n",
    "一つの訓練データについて、何回も繰り返し学習を行います"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-11-24 03:54:23.048070] Train Epoch: 1\tAverage loss: 0.216139\n",
      "[2019-11-24 04:04:42.645970] Train Epoch: 1\tAverage loss: 0.072563\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 3):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 評価モードにしよう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 評価してみよう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.46      0.51      1000\n",
      "           1       0.57      0.50      0.53      1000\n",
      "           2       0.34      0.22      0.27      1000\n",
      "           3       0.29      0.29      0.29      1000\n",
      "           4       0.47      0.08      0.13      1000\n",
      "           5       0.47      0.26      0.34      1000\n",
      "           6       0.30      0.76      0.43      1000\n",
      "           7       0.55      0.36      0.44      1000\n",
      "           8       0.52      0.57      0.54      1000\n",
      "           9       0.40      0.69      0.50      1000\n",
      "\n",
      "    accuracy                           0.42     10000\n",
      "   macro avg       0.45      0.42      0.40     10000\n",
      "weighted avg       0.45      0.42      0.40     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = []\n",
    "Y = []\n",
    "for i, (x,y) in enumerate(test_loader):\n",
    "    with torch.no_grad():\n",
    "        # データをGPUに対応\n",
    "        x = x.to(device)\n",
    "        # モデルへ適応\n",
    "        output = model(x)\n",
    "    pred += [int(l.argmax()) for l in output]\n",
    "    Y += [int(l) for l in y]\n",
    "\n",
    "# 予測結果を評価する\n",
    "print(classification_report(Y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
